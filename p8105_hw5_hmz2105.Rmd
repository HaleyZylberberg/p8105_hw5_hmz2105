---
title: "p8105_hw5_hmz2105"
author: Haley Zylberberg
output: github_document
---

```{r setup}
library (tidyverse)
set.seed(1234)
```

## Problem 2

Create a tidy dataframe of this dataset which includes participants among a control group and an experiment group with 8 weeks of measurement data taken.

```{r import and tidy dataset}
file_names = list.files(path = "data", pattern = "*.csv", full.names = TRUE)

data_list = map(file_names, ~read.csv(.x))

experiment_df = data.frame(file_name = file_names, do.call(rbind.data.frame, data_list)) |>
  separate(file_name, into = c("arm", "subject_id"), sep = "_") |>
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    names_prefix = "week_",
    values_to = "value"
  ) |>
 mutate(arm = gsub("data/", "", arm),
        subject_id= gsub(".csv", "", subject_id)) |>
  select (subject_id, arm, week, value)

```

```{r spaghetti plot}
experiment_df |>
ggplot(aes(x = week, y = value, color = arm)) +
  geom_point() + 
  geom_line(aes(group = interaction(subject_id, arm))) +
  labs(x = "Week", y = "Value", color = "Study Arm") +
  theme_minimal()
```

In this spaghetti plot we see that the experimental group had an increase in the value measured from week 1 through week 8 while the control group showed a slight decrease in the value measured over this time period.


## Problem 3

```{r simulation of ttest}

sim_mean_test = function(n = 30, mu, sigma = 5) {
  
  sim_data = tibble(
    x = rnorm(n, mean = mu, sd = sigma),
  )
  
  result = sim_data %>%
    summarize(
      mu_hat = mean(x),
      p_value = broom::tidy(t.test(x)) |> 
        pull(p.value) 
    )
  
  return(result)
}

mu_values <- c(0, 1, 2, 3, 4, 5, 6)


sim_results_df = expand_grid(
  mu = mu_values,
  dataset = 1:5000
) |>
mutate(
  estimate_df = pmap(list(n = 30, mu = mu, sigma = 5), sim_mean_test)
) |>
unnest(estimate_df)

```

Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of μ on the x axis. Describe the association between effect size and power.

* Make a plot showing the average estimate of μ̂ 
on the y axis (for all simulations and those where the null was rejected) and the true value of μ on the x axis. 

```{r plot mu}

mu_plot_df= 
sim_results_df |>
  group_by(mu) |>
  summarize(average_mu_hat = mean(mu_hat),
            average_rejected_mu_hat = mean(mu_hat[p_value < 0.05])
  )


  ggplot(mu_plot_df, aes(x = mu)) +
  geom_line(aes(y = average_mu_hat, color = "All Simulations")) +
  geom_point(aes(y = average_mu_hat, color = "All Simulations")) +
  geom_line(aes(y = average_rejected_mu_hat, color = "Null Rejected")) +
  geom_point(aes(y = average_rejected_mu_hat, color = "Null Rejected")) +
  labs(title = "Average Estimate of mu_hat vs. True Value of mu",
       x = "True Value of mu",
       y = "Average Estimate of mu_hat") +
  scale_color_manual(
    values = c("All Simulations" = "blue", "Null Rejected" = "red"),
    labels = c("All Simulations", "Null Rejected")
  ) +
  theme_minimal()
```


Is the sample average of μ̂  across tests for which the null is rejected approximately equal to the true value of μ
? Why or why not?
