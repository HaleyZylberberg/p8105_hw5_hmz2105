---
title: "p8105_hw5_hmz2105"
author: Haley Zylberberg
output: github_document
---

```{r setup}
library (tidyverse)
set.seed(1234)
```

# Problem 2

Create a tidy dataframe of this dataset which includes participants among a control group and an experiment group with 8 weeks of measurement data taken.

```{r import and tidy dataset}
file_names = list.files(path = "data", pattern = "*.csv", full.names = TRUE)

data_list = map(file_names, ~read.csv(.x))

experiment_df = data.frame(file_name = file_names, do.call(rbind.data.frame, data_list)) |>
  separate(file_name, into = c("arm", "subject_id"), sep = "_") |>
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    names_prefix = "week_",
    values_to = "value"
  ) |>
 mutate(arm = gsub("data/", "", arm),
        subject_id= gsub(".csv", "", subject_id)) |>
  select (subject_id, arm, week, value)

```

```{r spaghetti plot}
experiment_df |>
ggplot(aes(x = week, y = value, color = arm)) +
  geom_point() + 
  geom_line(aes(group = interaction(subject_id, arm))) +
  labs(x = "Week", y = "Value", color = "Study Arm") +
  theme_minimal()
```

In this spaghetti plot we see that the experimental group had an increase in the value measured from week 1 through week 8 while the control group showed a slight decrease in the value measured over this time period.


# Problem 3

## Explore whether a false null hypothesis will be rejected. 

To do this, will generate a dataset of 50000 values from the model x∼Normal[μ,σ], with the following design elements: n=30, σ=5, μ=0.For each dataset, save μ̂ and the p-value arising from a test of H:μ=0 using α=0.05. Then repeat the above for μ={1,2,3,4,5,6}.

```{r simulation of ttest}

sim_mean_test = function(n = 30, mu, sigma = 5) {
  
  sim_data = tibble(
    x = rnorm(n, mean = mu, sd = sigma),
  )
  
  result = sim_data %>%
    summarize(
      mu_hat = mean(x),
      p_value = broom::tidy(t.test(x)) |> 
        pull(p.value) 
    )
  
  return(result)
}

mu_values <- c(0, 1, 2, 3, 4, 5, 6)


sim_results_df = expand_grid(
  mu = mu_values,
  dataset = 1:5000
) |>
mutate(
  estimate_df = pmap(list(n = 30, mu = mu, sigma = 5), sim_mean_test)
) |>
unnest(estimate_df)

```

* Make a plot showing the proportion of times the null was rejected on the y axis and the true value of μ on the x axis.

```{r}
sim_results_df = sim_results_df |>
   mutate(reject_null = case_when(
    p_value < 0.05 ~ 1,
    TRUE ~ 0
  )) 

sim_results_df |>
  group_by(mu)|>
  summarize(proportion_null_rejected= sum(reject_null)/5000) |>
ggplot(aes(x = factor(mu), y = proportion_null_rejected)) +
  geom_bar(stat = "identity", fill = "royal blue") +
  labs(title = "Proportion Null Rejected vs. mu", x = "mu", y = "Proportion Null Rejected") 


```

Describe the association between effect size and power: 

  * A larger effect size is generally associated with higher statistical power, making it more likely for a study to detect a true effect. However, with a large enough sample size, even small effect sizes can be detected with high power.

* Make a plot showing the average estimate of μ̂ 
on the y axis (for all simulations and those where the null was rejected) and the true value of μ on the x axis. 

```{r plot mu}

mu_plot_df= 
sim_results_df |>
  group_by(mu) |>
  summarize(average_mu_hat = mean(mu_hat),
            average_rejected_mu_hat = mean(mu_hat[p_value < 0.05])
  )


  ggplot(mu_plot_df, aes(x = mu)) +
  geom_line(aes(y = average_mu_hat, color = "All Simulations")) +
  geom_point(aes(y = average_mu_hat, color = "All Simulations")) +
  geom_line(aes(y = average_rejected_mu_hat, color = "Null Rejected")) +
  geom_point(aes(y = average_rejected_mu_hat, color = "Null Rejected")) +
  labs(title = "Average Estimate of mu_hat vs. True Value of mu",
       x = "True Value of mu",
       y = "Average Estimate of mu_hat") +
  scale_color_manual(
    values = c("All Simulations" = "blue", "Null Rejected" = "red"),
    labels = c("All Simulations", "Null Rejected")
  ) +
  theme_minimal()
```


Is the sample average of μ̂ across tests for which the null is rejected approximately equal to the true value of μ? Why or why not?

  * The μ̂ across the tests where the null is rejected equals  μ as the values get larger. This occurs because the farther the u is from 0, the more likely it is to reject the null hypothesis on both tails. For example, when  μ̂= 1, the values between 1 and 0 will not be rejected because they are too close to u. 
